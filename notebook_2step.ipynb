{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**CELL 1 — Environment & repo**","metadata":{}},{"cell_type":"code","source":"# GPU: CUDA 11.8, PyTorch 2.0.1 su Kaggle\n!pip install --upgrade pip\n!pip install git+https://github.com/openai/CLIP.git\n# 1) Rimuovi ogni installazione pre-esistente  \n!pip uninstall -y kaolin\n\n# 2) Installa esattamente Torch 2.0.1 cu118 (l’ambiente Kaggle è già cu118, ma lo riallineiamo)\n!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 \\\n  -f https://download.pytorch.org/whl/cu118/torch_stable.html\n\n# 3) Installa la wheel ufficiale di Kaolin per Torch 2.0.1+cu118\n!pip install kaolin==0.17.0 \\\n  -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.0.1_cu118.html\n\n!pip install -q open3d==0.18.0 tqdm pillow\n!rm -rf /kaggle/working/Affordance_Highlighting_Project_2024\n!rm -rf /kaggle/working/output\n!git clone https://github.com/MirkoDiMa/Affordance_Highlighting_Project_2024.git\n%cd Affordance_Highlighting_Project_2024\nimport sys\n# Aggiungi la cartella principale del repo al PYTHONPATH\nsys.path.append('/kaggle/working/Affordance_Highlighting_Project_2024')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:25:59.142715Z","iopub.execute_input":"2025-08-22T15:25:59.143041Z","iopub.status.idle":"2025-08-22T15:26:13.833669Z","shell.execute_reply.started":"2025-08-22T15:25:59.143013Z","shell.execute_reply":"2025-08-22T15:26:13.832491Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (25.2)\nCollecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-e43uf2qi\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-e43uf2qi\n  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (25.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.0.1+cu118)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.15.2+cu118)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.14.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.0.0)\nRequirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->clip==1.0) (3.31.6)\nRequirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch->clip==1.0) (18.1.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch->clip==1.0) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.32.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->clip==1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->clip==1.0) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->clip==1.0) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->clip==1.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->clip==1.0) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision->clip==1.0) (2025.6.15)\nFound existing installation: kaolin 0.17.0\nUninstalling kaolin-0.17.0:\n  Successfully uninstalled kaolin-0.17.0\nLooking in links: https://download.pytorch.org/whl/cu118/torch_stable.html\nRequirement already satisfied: torch==2.0.1+cu118 in /usr/local/lib/python3.11/dist-packages (2.0.1+cu118)\nRequirement already satisfied: torchvision==0.15.2+cu118 in /usr/local/lib/python3.11/dist-packages (0.15.2+cu118)\nRequirement already satisfied: torchaudio==2.0.2+cu118 in /usr/local/lib/python3.11/dist-packages (2.0.2+cu118)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.18.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (4.14.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.1.6)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (2.0.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (2.32.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (11.2.1)\nRequirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.31.6)\nRequirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (18.1.8)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.15.2+cu118) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.15.2+cu118) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2025.6.15)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\nLooking in links: https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.0.1_cu118.html\nCollecting kaolin==0.17.0\n  Using cached https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.0.1_cu118/kaolin-0.17.0-cp311-cp311-linux_x86_64.whl (5.9 MB)\nRequirement already satisfied: ipycanvas in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (0.14.1)\nRequirement already satisfied: ipyevents in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (2.0.2)\nRequirement already satisfied: jupyter-client<8 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (7.4.9)\nRequirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (3.1.1)\nRequirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (6.5.1)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (0.2.2)\nRequirement already satisfied: usd-core in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (25.8)\nRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (1.26.4)\nRequirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (2.13.6)\nRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (11.2.1)\nRequirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (1.15.3)\nRequirement already satisfied: pygltflib in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (1.16.4)\nRequirement already satisfied: warp-lang in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (1.8.1)\nRequirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (7.34.0)\nRequirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (0.4)\nRequirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (5.8.1)\nRequirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (1.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (2.9.0.post0)\nRequirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (24.0.1)\nRequirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (5.7.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.9.2->jupyter-client<8->kaolin==0.17.0) (4.3.8)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client<8->kaolin==0.17.0) (1.17.0)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (1.9.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (8.2.1)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (3.1.3)\nRequirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipycanvas->kaolin==0.17.0) (8.1.5)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.0.15)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (3.0.51)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (4.9.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kaolin==0.17.0) (0.2.13)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->kaolin==0.17.0) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->kaolin==0.17.0) (0.7.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->kaolin==0.17.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->kaolin==0.17.0) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0->kaolin==0.17.0) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0->kaolin==0.17.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0->kaolin==0.17.0) (2024.2.0)\nRequirement already satisfied: dataclasses-json>=0.0.25 in /usr/local/lib/python3.11/dist-packages (from pygltflib->kaolin==0.17.0) (0.6.7)\nRequirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from pygltflib->kaolin==0.17.0) (1.2.18)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (0.9.0)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (25.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (1.1.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (4.14.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->pygltflib->kaolin==0.17.0) (1.17.2)\nInstalling collected packages: kaolin\nSuccessfully installed kaolin-0.17.0\nCloning into 'Affordance_Highlighting_Project_2024'...\nremote: Enumerating objects: 133, done.\u001b[K\nremote: Counting objects: 100% (113/113), done.\u001b[K\nremote: Compressing objects: 100% (86/86), done.\u001b[K\nremote: Total 133 (delta 47), reused 75 (delta 25), pack-reused 20 (from 1)\u001b[K\nReceiving objects: 100% (133/133), 7.76 MiB | 25.16 MiB/s, done.\nResolving deltas: 100% (47/47), done.\n/kaggle/working/Affordance_Highlighting_Project_2024\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"**CELL 2 — Config**","metadata":{}},{"cell_type":"code","source":"# =========================\n#         CONFIG\n# =========================\nimport os, json, copy, time, gc, random, numpy as np\nfrom pathlib import Path\n\n# Keep CPU libs conservative to avoid crashes on Kaggle\nos.environ[\"OMP_NUM_THREADS\"] = \"1\"\nos.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\nos.environ[\"MKL_NUM_THREADS\"] = \"1\"\n\nREPO_ROOT   = '/kaggle/working/Affordance_Highlighting_Project_2024'\nOUTPUT_ROOT = '/kaggle/working/output'\nPath(OUTPUT_ROOT).mkdir(parents=True, exist_ok=True)\n\n# We only load point clouds from the repository (no mesh fallback)\nPLY_RELATIVE   = \"data/candle_15000pts.ply\"   # << change if needed\nUSE_PLY_DIRECT = True                         # << must be True\n\n# Base OBJ kept only for naming; not used to sample PCD\nOBJ_RELATIVE = \"data/candle.obj\"\n\nSAFE_MODE = False  # Does not change hyperparameters; just controls n_iter below\n\nexp_config = {\n    \"prompt\": \"A 3D render of a gray candle with highlighted hat\",\n    \"seed\": 45,\n    \"clip_model_name\": \"ViT-L/14\",\n    \"render_res\": 224,\n    \"n_views\": 5,\n    \"learning_rate\": 1e-5,\n    \"n_iter\": 400 if SAFE_MODE else 2500,\n    \"n_augs\": 5,\n    \"clipavg\": \"view\",\n    \"mlp_input_dim\": 3,\n    \"mlp_hidden_dim\": 256,\n    \"mlp_num_layers\": 6,\n    \"mlp_out_dim\": 2,\n    \"positional_encoding\": False,\n    \"sigma\": 5.0,\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:26:13.835432Z","iopub.execute_input":"2025-08-22T15:26:13.835661Z","iopub.status.idle":"2025-08-22T15:26:13.842257Z","shell.execute_reply.started":"2025-08-22T15:26:13.835637Z","shell.execute_reply":"2025-08-22T15:26:13.841454Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"**CELL 3 — Imports & small utilities**","metadata":{}},{"cell_type":"code","source":"# =========================\n#   IMPORTS & HELPERS\n# =========================\nimport torch, torch.nn as nn, torchvision\nimport clip\nimport open3d as o3d\nfrom torchvision import transforms\nfrom tqdm import tqdm\n\nfrom render import Renderer\nfrom mesh import Mesh\n\n# Normalizer may be named differently across repos\ntry:\n    from Normalization import MeshNormalizer\nexcept Exception:\n    from MeshNormalizer import MeshNormalizer\n\nfrom utils import device, color_mesh\ntry:\n    from utils import FourierFeatureTransform\n    HAS_FOURIER = True\nexcept Exception:\n    HAS_FOURIER = False\n\n\ndef set_seed(seed: int):\n    \"\"\"Deterministic seeding where feasible.\"\"\"\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n\n\nclass NeuralHighlighter(nn.Module):\n    \"\"\"Simple MLP that outputs per-vertex soft assignments (2 classes).\"\"\"\n    def __init__(self, depth, width, out_dim, input_dim=3, positional_encoding=False, sigma=5.0):\n        super().__init__()\n        layers = []\n        if positional_encoding and HAS_FOURIER:\n            layers.append(FourierFeatureTransform(input_dim, width, sigma))\n            layers.append(nn.Linear(width * 2 + input_dim, width))\n        else:\n            layers.append(nn.Linear(input_dim, width))\n        layers += [nn.ReLU(), nn.LayerNorm([width])]\n\n        for _ in range(depth):\n            layers += [nn.Linear(width, width), nn.ReLU(), nn.LayerNorm([width])]\n\n        layers += [nn.Linear(width, out_dim), nn.Softmax(dim=1)]\n        self.mlp = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.mlp(x)\n\n\ndef get_clip_model(name: str):\n    model, preprocess = clip.load(name, device=device, jit=False)\n    return model, preprocess\n\n\ndef save_renders(dirpath, i, rendered_images, name=None):\n    Path(os.path.join(dirpath, 'renders')).mkdir(parents=True, exist_ok=True)\n    if name is None:\n        name = f\"renders/iter_{i}.jpg\"\n    torchvision.utils.save_image(rendered_images, os.path.join(dirpath, name))\n\n\ndef save_exp_config(config, output_dir):\n    import csv\n    Path(output_dir).mkdir(parents=True, exist_ok=True)\n    with open(os.path.join(output_dir, 'experiment_config.json'), 'w') as f:\n        json.dump(config, f, indent=2)\n    csv_path = os.path.join(output_dir, 'experiments_summary.csv')\n    write_header = not os.path.exists(csv_path)\n    with open(csv_path, 'a', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=config.keys())\n        if write_header: writer.writeheader()\n        writer.writerow(config)\n\n\ndef save_final_results(log_dir, name, mesh, mlp, vertices, colors, render, background):\n    \"\"\"Export final PLY (per-vertex colors) and a small render strip.\"\"\"\n    mlp.eval()\n    with torch.no_grad():\n        probs   = mlp(vertices)\n        max_idx = torch.argmax(probs, 1, keepdim=True)\n        one_hot = torch.zeros_like(probs).to(device).scatter_(1, max_idx, 1)\n\n        highlight = torch.tensor([204, 255, 0], device=device)\n        gray      = torch.tensor([180, 180, 180], device=device)\n        palette   = torch.stack((highlight/255, gray/255)).to(device)\n\n        color_mesh(one_hot, mesh, palette)\n\n        rendered_images, _, _ = render.render_views(\n            mesh, num_views=5, show=False, center_azim=0, center_elev=0,\n            std=4, return_views=True, lighting=True, background=background)\n\n        final_color = torch.where(max_idx==0, highlight, gray)  # (V,3), uint8-like in export\n        mesh.export(os.path.join(log_dir, f\"{name}.ply\"), extension=\"ply\", color=final_color)\n        save_renders(log_dir, 0, rendered_images, name='final_render.jpg')\n\n\ndef clip_loss(rendered_images, text_embedding, clip_model, clip_transform, augment_transform, n_augs, clipavg=\"view\"):\n    \"\"\"CLIP loss with optional augment accumulation (matches your original logic).\"\"\"\n    if n_augs == 0:\n        clip_imgs = clip_transform(rendered_images)\n        enc = clip_model.encode_image(clip_imgs)\n        enc = enc / enc.norm(dim=1, keepdim=True)\n        txt = text_embedding / text_embedding.norm(dim=1, keepdim=True)\n        if clipavg == \"view\":\n            return -torch.cosine_similarity(enc.mean(0, keepdim=True), txt, dim=1)\n        else:\n            return -torch.mean(torch.cosine_similarity(enc, txt, dim=1))\n    else:\n        loss = 0.0\n        for _ in range(n_augs):\n            aug = augment_transform(rendered_images)\n            enc = clip_model.encode_image(aug)\n            enc = enc / enc.norm(dim=1, keepdim=True)\n            txt = text_embedding / text_embedding.norm(dim=1, keepdim=True)\n            if clipavg == \"view\":\n                loss -= torch.cosine_similarity(enc.mean(0, keepdim=True), txt, dim=1)\n            else:\n                loss -= torch.mean(torch.cosine_similarity(enc, txt, dim=1))\n        return loss\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:26:13.843426Z","iopub.execute_input":"2025-08-22T15:26:13.843723Z","iopub.status.idle":"2025-08-22T15:26:18.899609Z","shell.execute_reply.started":"2025-08-22T15:26:13.843691Z","shell.execute_reply":"2025-08-22T15:26:18.898701Z"}},"outputs":[{"name":"stdout","text":"Jupyter environment detected. Enabling Open3D WebVisualizer.\n[Open3D INFO] WebRTC GUI backend enabled.\n[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\nWarp 1.8.1 initialized:\n   CUDA Toolkit 12.8, Driver 12.6\n   Devices:\n     \"cpu\"      : \"x86_64\"\n     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n     \"cuda:1\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n   CUDA peer access:\n     Not supported\n   Kernel cache:\n     /root/.cache/warp/1.8.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"**CELL 4 — Init CLIP & prompt**","metadata":{}},{"cell_type":"code","source":"# =========================\n#   INIT CLIP & COLORS\n# =========================\nset_seed(exp_config[\"seed\"])\nclip_model, _ = get_clip_model(exp_config[\"clip_model_name\"])\n\nres = exp_config[\"render_res\"]\nclip_normalizer = transforms.Normalize(\n    (0.48145466, 0.4578275, 0.40821073),\n    (0.26862954, 0.26130258, 0.27577711)\n)\nclip_transform = transforms.Compose([\n    transforms.Resize((res, res), antialias=False),\n    clip_normalizer\n])\naugment_transform = transforms.Compose([\n    transforms.RandomResizedCrop(res, scale=(1, 1), antialias=False),\n    transforms.RandomPerspective(fill=1, distortion_scale=0.5, p=0.8),\n    clip_normalizer\n])\n\nwith torch.no_grad():\n    prompt_token = clip.tokenize([exp_config[\"prompt\"]]).to(device)\n    encoded_text = clip_model.encode_text(prompt_token)\n    encoded_text = encoded_text / encoded_text.norm(dim=1, keepdim=True)\n\n# fixed 2-color palette (highlighter + gray)\ncolors = torch.tensor([[204/255, 1.0, 0.0],\n                       [180/255, 180/255, 180/255]], device=device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:26:18.901668Z","iopub.execute_input":"2025-08-22T15:26:18.902128Z","iopub.status.idle":"2025-08-22T15:26:31.208921Z","shell.execute_reply.started":"2025-08-22T15:26:18.902077Z","shell.execute_reply":"2025-08-22T15:26:31.208311Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"**CELL 5 — Load PLY**","metadata":{}},{"cell_type":"code","source":"# =========================\n#   LOAD PLY FROM REPO\n# =========================\nPOINTCLOUD_DIR = os.path.join(OUTPUT_ROOT, 'pointcloud')\nPCD_DIR        = os.path.join(OUTPUT_ROOT, 'pcd')\nPath(POINTCLOUD_DIR).mkdir(parents=True, exist_ok=True)\nPath(PCD_DIR).mkdir(parents=True, exist_ok=True)\n\nassert USE_PLY_DIRECT, \"This notebook expects PLYs to be provided in the repo.\"\nply_abs = os.path.join(REPO_ROOT, PLY_RELATIVE)\nif not os.path.exists(ply_abs):\n    raise FileNotFoundError(f\"PLY not found: {ply_abs}\")\n\npcd = o3d.io.read_point_cloud(ply_abs)\nif len(pcd.points) == 0:\n    raise RuntimeError(f\"PLY is empty: {ply_abs}\")\n\n# Light-weight normals for robustness\npcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=16))\npcd.orient_normals_consistent_tangent_plane(24)\n\nobjbase = Path(ply_abs).stem\npcd_out = os.path.join(POINTCLOUD_DIR, f\"{objbase}.ply\")\no3d.io.write_point_cloud(pcd_out, pcd)\nprint(f\"[PCD] Loaded: {ply_abs}  | N points = {len(pcd.points)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:26:31.209870Z","iopub.execute_input":"2025-08-22T15:26:31.210073Z","iopub.status.idle":"2025-08-22T15:26:31.778144Z","shell.execute_reply.started":"2025-08-22T15:26:31.210054Z","shell.execute_reply":"2025-08-22T15:26:31.777472Z"}},"outputs":[{"name":"stdout","text":"[PCD] Loaded: /kaggle/working/Affordance_Highlighting_Project_2024/data/candle_15000pts.ply  | N points = 15000\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"**CELL 6 — BPA reconstruction**","metadata":{}},{"cell_type":"code","source":"# =========================\n#   BPA RECONSTRUCTION\n# =========================\ndef reconstruct_mesh_bpa(ply_path: str, obj_output_path: str):\n    pcd = o3d.io.read_point_cloud(ply_path)\n    print(f\"[RECON] Points: {len(pcd.points)}\")\n\n    # Radii based on median NN distance (dense multi-scale list helps close small gaps)\n    dists = np.asarray(pcd.compute_nearest_neighbor_distance())\n    med = float(np.median(dists)) if dists.size else 0.01\n    radii = o3d.utility.DoubleVector([med*1.2, med*1.6, med*2.0, med*2.4, med*3.0, med*3.8])\n\n    mesh = o3d.geometry.TriangleMesh.create_from_point_cloud_ball_pivoting(pcd, radii)\n\n    # Cleanup + normals\n    mesh.remove_unreferenced_vertices()\n    mesh.remove_degenerate_triangles()\n    mesh.remove_duplicated_vertices()\n    mesh.remove_duplicated_triangles()\n    mesh.remove_non_manifold_edges()\n\n    # Crop to PCD AABB (slightly expanded) to remove any outer shell\n    bbox = pcd.get_axis_aligned_bounding_box().scale(1.01, pcd.get_axis_aligned_bounding_box().get_center())\n    mesh = mesh.crop(bbox)\n\n    mesh.compute_vertex_normals()\n\n    # Gentle smoothing\n    if hasattr(mesh, \"filter_smooth_taubin\"):\n        mesh = mesh.filter_smooth_taubin(number_of_iterations=10)\n    else:\n        mesh = mesh.filter_smooth_simple(number_of_iterations=3)\n\n    o3d.io.write_triangle_mesh(obj_output_path, mesh)\n    print(f\"[RECON] BPA -> {obj_output_path}\")\n\nrecon_obj_abs = os.path.join(PCD_DIR, f\"{objbase}_frompc.obj\")\nreconstruct_mesh_bpa(pcd_out, recon_obj_abs)\n\ndel pcd; gc.collect()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:26:31.779018Z","iopub.execute_input":"2025-08-22T15:26:31.779269Z","iopub.status.idle":"2025-08-22T15:26:32.432182Z","shell.execute_reply.started":"2025-08-22T15:26:31.779238Z","shell.execute_reply":"2025-08-22T15:26:32.431073Z"}},"outputs":[{"name":"stdout","text":"[RECON] Points: 15000\n[RECON] BPA -> /kaggle/working/output/pcd/candle_15000pts_frompc.obj\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"192"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"**CELL 7 — Train 3D Highlighter on reconstructed mesh**","metadata":{}},{"cell_type":"code","source":"# =========================\n#   TRAIN ON RECON MESH\n# =========================\nexp_config_pc = copy.deepcopy(exp_config)\nexp_config_pc[\"obj_path\"]   = recon_obj_abs\nexp_config_pc[\"output_dir\"] = PCD_DIR\nPath(os.path.join(exp_config_pc[\"output_dir\"], 'renders')).mkdir(parents=True, exist_ok=True)\n\nrenderer = Renderer(dim=(exp_config_pc[\"render_res\"], exp_config_pc[\"render_res\"]))\nmesh_pc  = Mesh(exp_config_pc[\"obj_path\"])\nMeshNormalizer(mesh_pc)()\n\nbackground  = torch.tensor((1., 1., 1.), device=device)\nvertices_pc = mesh_pc.vertices.clone()\nn_views     = exp_config_pc[\"n_views\"]\n\nmlp = NeuralHighlighter(\n    depth=exp_config_pc[\"mlp_num_layers\"],\n    width=exp_config_pc[\"mlp_hidden_dim\"],\n    out_dim=exp_config_pc[\"mlp_out_dim\"],\n    input_dim=exp_config_pc[\"mlp_input_dim\"],\n    positional_encoding=exp_config_pc[\"positional_encoding\"],\n    sigma=exp_config_pc[\"sigma\"]\n).to(device)\n\noptim = torch.optim.Adam(mlp.parameters(), exp_config_pc[\"learning_rate\"])\n\nbest_loss, best_iter, best_state = float('inf'), -1, None\nlosses = []\nstart_time = time.time()\n\nfor i in tqdm(range(exp_config_pc[\"n_iter\"])):\n    optim.zero_grad()\n\n    pred_class = mlp(vertices_pc)\n    color_mesh(pred_class, mesh_pc, colors)\n\n    rendered_images, elev, azim = renderer.render_views(\n        mesh_pc, num_views=n_views, show=False,\n        center_azim=0, center_elev=0, std=4,\n        return_views=True, lighting=True, background=background\n    )\n\n    loss = clip_loss(\n        rendered_images, encoded_text, clip_model,\n        clip_transform, augment_transform, exp_config_pc[\"n_augs\"],\n        clipavg=exp_config_pc[\"clipavg\"]\n    )\n    (loss if torch.is_tensor(loss) else torch.tensor(loss, device=device)).mean().backward()\n    optim.step()\n\n    with torch.no_grad():\n        val = loss.item() if torch.is_tensor(loss) else float(loss)\n        losses.append(val)\n        if val < best_loss:\n            best_loss  = val\n            best_iter  = i\n            best_state = copy.deepcopy(mlp.state_dict())\n\n    if i % 100 == 0:\n        torch.cuda.empty_cache(); gc.collect()\n        print(f\"Last 100 CLIP score (pcd): {np.mean(losses[-100:])}\")\n        save_renders(exp_config_pc[\"output_dir\"], i, rendered_images)\n        with open(os.path.join(exp_config_pc[\"output_dir\"], \"training_info.txt\"), \"a\") as f:\n            f.write(f\"[PCD] Iter {i} | Prompt: {exp_config_pc['prompt']} | Last100 avg: {np.mean(losses[-100:])} | Loss: {losses[-1]}\\n\")\n\n# Restore best and save artifacts\nmlp.load_state_dict(best_state)\nexp_config_pc[\"best_iter\"]              = best_iter\nexp_config_pc[\"best_clip_score\"]        = -best_loss\nexp_config_pc[\"final_clip_score\"]       = -losses[-1]\nexp_config_pc[\"avg_clip_score_last100\"] = -float(np.mean(losses[-100:]))\nexp_config_pc[\"runtime_seconds\"]        = time.time() - start_time\nsave_exp_config(exp_config_pc, exp_config_pc[\"output_dir\"])\n\nobjbase_pc = Path(exp_config_pc[\"obj_path\"]).stem\nsave_final_results(\n    exp_config_pc[\"output_dir\"],\n    f\"{objbase_pc}_best_iter{best_iter}\",\n    mesh_pc, mlp, vertices_pc, colors, renderer, background\n)\n\nwith open(os.path.join(exp_config_pc[\"output_dir\"], \"prompt.txt\"), \"w\") as f:\n    f.write(exp_config_pc[\"prompt\"])\n\nprint(f\"[DONE] Best iter: {best_iter}, best CLIP score: {-best_loss:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-22T15:26:32.433190Z","iopub.execute_input":"2025-08-22T15:26:32.433699Z","iopub.status.idle":"2025-08-22T16:17:20.064842Z","shell.execute_reply.started":"2025-08-22T15:26:32.433678Z","shell.execute_reply":"2025-08-22T16:17:20.063957Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 1/2500 [00:01<1:18:42,  1.89s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.556640625\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 101/2500 [01:56<52:16,  1.31s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.666103515625\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 201/2500 [03:56<51:07,  1.33s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.709755859375\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 301/2500 [05:57<49:26,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.71279296875\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 401/2500 [08:00<47:11,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.715419921875\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 501/2500 [10:02<44:57,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.717099609375\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 601/2500 [12:04<42:42,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.7183203125\n","output_type":"stream"},{"name":"stderr","text":" 28%|██▊       | 701/2500 [14:06<40:37,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.71568359375\n","output_type":"stream"},{"name":"stderr","text":" 32%|███▏      | 801/2500 [16:08<38:12,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.70615234375\n","output_type":"stream"},{"name":"stderr","text":" 36%|███▌      | 901/2500 [18:11<36:03,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.71875\n","output_type":"stream"},{"name":"stderr","text":" 40%|████      | 1001/2500 [20:13<33:43,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.718095703125\n","output_type":"stream"},{"name":"stderr","text":" 44%|████▍     | 1101/2500 [22:15<31:26,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.72951171875\n","output_type":"stream"},{"name":"stderr","text":" 48%|████▊     | 1201/2500 [24:17<29:08,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.7227734375\n","output_type":"stream"},{"name":"stderr","text":" 52%|█████▏    | 1301/2500 [26:20<26:55,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.72166015625\n","output_type":"stream"},{"name":"stderr","text":" 56%|█████▌    | 1401/2500 [28:22<24:38,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.72421875\n","output_type":"stream"},{"name":"stderr","text":" 60%|██████    | 1501/2500 [30:24<22:26,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.721533203125\n","output_type":"stream"},{"name":"stderr","text":" 64%|██████▍   | 1601/2500 [32:26<20:07,  1.34s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.71845703125\n","output_type":"stream"},{"name":"stderr","text":" 68%|██████▊   | 1701/2500 [34:28<17:57,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.725615234375\n","output_type":"stream"},{"name":"stderr","text":" 72%|███████▏  | 1801/2500 [36:30<15:45,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.720625\n","output_type":"stream"},{"name":"stderr","text":" 76%|███████▌  | 1901/2500 [38:33<13:26,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.731025390625\n","output_type":"stream"},{"name":"stderr","text":" 80%|████████  | 2001/2500 [40:35<11:12,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.718046875\n","output_type":"stream"},{"name":"stderr","text":" 84%|████████▍ | 2101/2500 [42:37<08:59,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.724306640625\n","output_type":"stream"},{"name":"stderr","text":" 88%|████████▊ | 2201/2500 [44:39<06:43,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.73392578125\n","output_type":"stream"},{"name":"stderr","text":" 92%|█████████▏| 2301/2500 [46:42<04:28,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.732705078125\n","output_type":"stream"},{"name":"stderr","text":" 96%|█████████▌| 2401/2500 [48:44<02:13,  1.35s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score (pcd): -1.716943359375\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [50:44<00:00,  1.22s/it]\n","output_type":"stream"},{"name":"stdout","text":"[DONE] Best iter: 1692, best CLIP score: 1.8750\n","output_type":"stream"}],"execution_count":7}]}