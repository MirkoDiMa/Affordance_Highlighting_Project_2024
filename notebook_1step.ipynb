{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# GPU: CUDA 11.8, PyTorch 2.0.1 su Kaggle\n!pip install --upgrade pip\n!pip install git+https://github.com/openai/CLIP.git\n# 1) Rimuovi ogni installazione pre-esistente  \n!pip uninstall -y kaolin\n\n# 2) Installa esattamente Torch 2.0.1 cu118 (l’ambiente Kaggle è già cu118, ma lo riallineiamo)\n!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 \\\n  -f https://download.pytorch.org/whl/cu118/torch_stable.html\n\n# 3) Installa la wheel ufficiale di Kaolin per Torch 2.0.1+cu118\n!pip install kaolin==0.17.0 \\\n  -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.0.1_cu118.html\n\n!pip install tqdm pillow\n!rm -rf /kaggle/working/Affordance_Highlighting_Project_2024\n!rm -rf /kaggle/working/output\n!git clone https://github.com/MirkoDiMa/Affordance_Highlighting_Project_2024.git\n%cd Affordance_Highlighting_Project_2024\nimport sys\n# Aggiungi la cartella principale del repo al PYTHONPATH\nsys.path.append('/kaggle/working/Affordance_Highlighting_Project_2024')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:01:15.595477Z","iopub.execute_input":"2025-07-28T10:01:15.595667Z","iopub.status.idle":"2025-07-28T10:04:36.021367Z","shell.execute_reply.started":"2025-07-28T10:01:15.595650Z","shell.execute_reply":"2025-07-28T10:04:36.020635Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1.1\nCollecting git+https://github.com/openai/CLIP.git\n  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-wnecqzee\n  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-wnecqzee\n  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting ftfy (from clip==1.0)\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (25.0)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.14.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.2.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->clip==1.0) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->clip==1.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->clip==1.0) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->clip==1.0) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->clip==1.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->clip==1.0) (2024.2.0)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m171.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m104.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: clip\n\u001b[33m  DEPRECATION: Building 'clip' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'clip'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n\u001b[0m  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=9ed3e6346e264ea95d492f96d760551eb0dc5e8ec47236014176ece1628453bd\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ul4rm85e/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\nSuccessfully built clip\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12\n\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82/12\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━\u001b[0m \u001b[32m 0/12\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.6.820m [nvidia-nvjitlink-cu12]\n\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.6.82:0m \u001b[32m 0/12\u001b[0m [nvidia-nvjitlink-cu12]\n\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.6.82━━━━━━━\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-curand-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cufft-cu12━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.2.3.61━━\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-curand-cu12]\n\u001b[2K    Uninstalling nvidia-cufft-cu12-11.2.3.61:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/12\u001b[0m [nvidia-curand-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61━━━━━━━━\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82m \u001b[32m 2/12\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:━━━━━━━━━━━━\u001b[0m \u001b[32m 2/12\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82[0m \u001b[32m 2/12\u001b[0m [nvidia-cufft-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/12\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82[0m \u001b[32m 3/12\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/12\u001b[0m [nvidia-cuda-runtime-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/12\u001b[0m [nvidia-cuda-nvrtc-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82━━━━━\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cublas-cu12m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.5.3.2━━\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K    Uninstalling nvidia-cublas-cu12-12.5.3.2:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/12\u001b[0m [nvidia-cuda-cupti-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cusparse-cu1290m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/12\u001b[0m [nvidia-cublas-cu12]\n\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.1.3━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.1.3:0m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cudnn-cu121m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.3.0.75━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/12\u001b[0m [nvidia-cusparse-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75━━━━━━━━━\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K  Attempting uninstall: nvidia-cusolver-cu1290m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.6.3.83[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m 9/12\u001b[0m [nvidia-cudnn-cu12]\n\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83━━━━━\u001b[0m \u001b[32m10/12\u001b[0m [nvidia-cusolver-cu12]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/12\u001b[0m [clip]2m10/12\u001b[0m [nvidia-cusolver-cu12]\n\u001b[1A\u001b[2KSuccessfully installed clip-1.0 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n\u001b[33mWARNING: Skipping kaolin as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mLooking in links: https://download.pytorch.org/whl/cu118/torch_stable.html\nCollecting torch==2.0.1+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp311-cp311-linux_x86_64.whl (2267.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting torchvision==0.15.2+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp311-cp311-linux_x86_64.whl (6.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m121.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting torchaudio==2.0.2+cu118\n  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp311-cp311-linux_x86_64.whl (4.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m90.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.18.0)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (4.14.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1+cu118) (3.1.6)\nCollecting triton==2.0.0 (from torch==2.0.1+cu118)\n  Downloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (2.32.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2+cu118) (11.2.1)\nRequirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1+cu118) (3.31.6)\nCollecting lit (from triton==2.0.0->torch==2.0.1+cu118)\n  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1+cu118) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision==0.15.2+cu118) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision==0.15.2+cu118) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision==0.15.2+cu118) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision==0.15.2+cu118) (2024.2.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2+cu118) (2025.6.15)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1+cu118) (1.3.0)\nDownloading triton-2.0.0-1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m120.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\nInstalling collected packages: lit, triton, torch, torchvision, torchaudio\n\u001b[2K  Attempting uninstall: triton\n\u001b[2K    Found existing installation: triton 3.2.0\n\u001b[2K    Uninstalling triton-3.2.0:\n\u001b[2K      Successfully uninstalled triton-3.2.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [triton]\n\u001b[2K  Attempting uninstall: torchm\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [triton]\n\u001b[2K    Found existing installation: torch 2.6.0+cu124━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [triton]\n\u001b[2K    Uninstalling torch-2.6.0+cu124:[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K      Successfully uninstalled torch-2.6.0+cu124━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K  Attempting uninstall: torchvision[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K    Found existing installation: torchvision 0.21.0+cu124━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K    Uninstalling torchvision-0.21.0+cu124:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/5\u001b[0m [torch]\n\u001b[2K      Successfully uninstalled torchvision-0.21.0+cu124━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [torchvision]\n\u001b[2K  Attempting uninstall: torchaudio0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [torchvision]\n\u001b[2K    Found existing installation: torchaudio 2.6.0+cu124━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [torchvision]\n\u001b[2K    Uninstalling torchaudio-2.6.0+cu124:0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3/5\u001b[0m [torchvision]\n\u001b[2K      Successfully uninstalled torchaudio-2.6.0+cu124m\u001b[90m━━━━━━━\u001b[0m \u001b[32m4/5\u001b[0m [torchaudio]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [torchaudio]5\u001b[0m [torchaudio]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npytorch-lightning 2.5.2 requires torch>=2.1.0, but you have torch 2.0.1+cu118 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed lit-18.1.8 torch-2.0.1+cu118 torchaudio-2.0.2+cu118 torchvision-0.15.2+cu118 triton-2.0.0\nLooking in links: https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.0.1_cu118.html\nCollecting kaolin==0.17.0\n  Downloading https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.0.1_cu118/kaolin-0.17.0-cp311-cp311-linux_x86_64.whl (5.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting ipycanvas (from kaolin==0.17.0)\n  Downloading ipycanvas-0.13.3-py2.py3-none-any.whl.metadata (6.3 kB)\nRequirement already satisfied: ipyevents in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (2.0.2)\nCollecting jupyter-client<8 (from kaolin==0.17.0)\n  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (3.1.1)\nRequirement already satisfied: tornado in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (6.5.1)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (0.2.2)\nCollecting usd-core (from kaolin==0.17.0)\n  Downloading usd_core-25.5.1-cp311-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (1.26.4)\nRequirement already satisfied: pybind11 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (2.13.6)\nRequirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (11.2.1)\nRequirement already satisfied: tqdm>=4.51.0 in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (4.67.1)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (1.15.3)\nRequirement already satisfied: pygltflib in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (1.16.4)\nCollecting warp-lang (from kaolin==0.17.0)\n  Downloading warp_lang-1.8.0-py3-none-manylinux_2_28_x86_64.whl.metadata (32 kB)\nRequirement already satisfied: ipython in /usr/local/lib/python3.11/dist-packages (from kaolin==0.17.0) (7.34.0)\nRequirement already satisfied: entrypoints in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (0.4)\nRequirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (5.8.1)\nRequirement already satisfied: nest-asyncio>=1.5.4 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (1.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (2.9.0.post0)\nRequirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (24.0.1)\nRequirement already satisfied: traitlets in /usr/local/lib/python3.11/dist-packages (from jupyter-client<8->kaolin==0.17.0) (5.7.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.0->kaolin==0.17.0) (2.4.1)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.9.2->jupyter-client<8->kaolin==0.17.0) (4.3.8)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->jupyter-client<8->kaolin==0.17.0) (1.17.0)\nRequirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (1.9.0)\nRequirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (8.2.1)\nRequirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (2.2.0)\nRequirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (3.1.6)\nRequirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (3.0.2)\nRequirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask->kaolin==0.17.0) (3.1.3)\nRequirement already satisfied: ipywidgets<9,>=7.6.0 in /usr/local/lib/python3.11/dist-packages (from ipycanvas->kaolin==0.17.0) (8.1.5)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (4.0.14)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.11/dist-packages (from ipywidgets<9,>=7.6.0->ipycanvas->kaolin==0.17.0) (3.0.15)\nRequirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (75.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (0.19.2)\nRequirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (4.4.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (3.0.51)\nRequirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (2.19.2)\nRequirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython->kaolin==0.17.0) (4.9.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->kaolin==0.17.0) (0.2.13)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython->kaolin==0.17.0) (0.8.4)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython->kaolin==0.17.0) (0.7.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->kaolin==0.17.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.0->kaolin==0.17.0) (2022.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.0->kaolin==0.17.0) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.0->kaolin==0.17.0) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.0->kaolin==0.17.0) (2024.2.0)\nRequirement already satisfied: dataclasses-json>=0.0.25 in /usr/local/lib/python3.11/dist-packages (from pygltflib->kaolin==0.17.0) (0.6.7)\nRequirement already satisfied: deprecated in /usr/local/lib/python3.11/dist-packages (from pygltflib->kaolin==0.17.0) (1.2.18)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (0.9.0)\nRequirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.11/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (25.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (1.1.0)\nRequirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json>=0.0.25->pygltflib->kaolin==0.17.0) (4.14.0)\nRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated->pygltflib->kaolin==0.17.0) (1.17.2)\nDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\nDownloading ipycanvas-0.13.3-py2.py3-none-any.whl (125 kB)\nDownloading usd_core-25.5.1-cp311-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m126.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading warp_lang-1.8.0-py3-none-manylinux_2_28_x86_64.whl (129.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: usd-core, jupyter-client, warp-lang, ipycanvas, kaolin\n\u001b[2K  Attempting uninstall: jupyter-client━━━━━━━━━━\u001b[0m \u001b[32m0/5\u001b[0m [usd-core]\n\u001b[2K    Found existing installation: jupyter_client 8.6.3m0/5\u001b[0m [usd-core]\n\u001b[2K    Uninstalling jupyter_client-8.6.3:━━━━━━\u001b[0m \u001b[32m0/5\u001b[0m [usd-core]\n\u001b[2K      Successfully uninstalled jupyter_client-8.6.3━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1/5\u001b[0m [jupyter-client]\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [kaolin]2m4/5\u001b[0m [kaolin]as]ient]\n\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed ipycanvas-0.13.3 jupyter-client-7.4.9 kaolin-0.17.0 usd-core-25.5.1 warp-lang-1.8.0\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\nCloning into 'Affordance_Highlighting_Project_2024'...\nremote: Enumerating objects: 96, done.\u001b[K\nremote: Counting objects: 100% (76/76), done.\u001b[K\nremote: Compressing objects: 100% (57/57), done.\u001b[K\nremote: Total 96 (delta 31), reused 55 (delta 17), pack-reused 20 (from 1)\u001b[K\nReceiving objects: 100% (96/96), 1.82 MiB | 21.23 MiB/s, done.\nResolving deltas: 100% (31/31), done.\n/kaggle/working/Affordance_Highlighting_Project_2024\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ─── EXPERIMENT CONFIG ──────────────────────────────────────────────────────────\nexp_config = {\n    # Prompt\n    \"prompt\": \"A 3D render of a gray candle with highlighted hat\",\n\n    # Seed & determinismo\n    \"seed\": 45,\n\n    # Dati & percorsi\n    \"obj_path\":        \"data/candle.obj\",\n    \"output_dir\":      \"/kaggle/working/output\",\n\n    # CLIP\n    \"clip_model_name\": \"ViT-L/14\",\n\n    # MLP\n    \"mlp_input_dim\":   3,\n    \"mlp_hidden_dim\":  256,\n    \"mlp_num_layers\":  8,\n    \"mlp_out_dim\":     2,\n    \"positional_encoding\": False,\n    \"sigma\":           5.0,\n\n    # Training\n    \"render_res\":      224,\n    \"n_views\":         8,\n    \"learning_rate\":   1e-4,\n    \"n_iter\":          2500,\n    \"n_augs\":          5,\n    \"clipavg\":         \"view\",\n\n    # Augmentation\n    \"aug_type\":        \"RandomPerspective\",\n    \"aug_params\": {\n        \"distortion_scale\": 0.5,\n        \"p\":               0.8,\n    },\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:04:36.022259Z","iopub.execute_input":"2025-07-28T10:04:36.022556Z","iopub.status.idle":"2025-07-28T10:04:36.027682Z","shell.execute_reply.started":"2025-07-28T10:04:36.022528Z","shell.execute_reply":"2025-07-28T10:04:36.026914Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import clip\nimport copy\nimport json\nimport kaolin as kal\nimport kaolin.ops.mesh\nimport numpy as np\nimport os\nimport random\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport time\n\nfrom itertools import permutations, product\nfrom Normalization import MeshNormalizer\nfrom mesh import Mesh\nfrom pathlib import Path\nfrom render import Renderer\nfrom tqdm import tqdm\nfrom torch.autograd import grad\nfrom torchvision import transforms\nfrom utils import device, color_mesh\nfrom utils import FourierFeatureTransform\n\nclass NeuralHighlighter(nn.Module):\n    def __init__(self, depth, width, out_dim, input_dim=3, positional_encoding=False, sigma=5.0):\n        super(NeuralHighlighter, self).__init__()\n        layers = []\n        if positional_encoding:\n            layers.append(FourierFeatureTransform(input_dim, width, sigma))\n            layers.append(nn.Linear(width * 2 + input_dim, width))\n            layers.append(nn.ReLU())\n            layers.append(nn.LayerNorm([width]))\n        else:\n            layers.append(nn.Linear(input_dim, width))\n            layers.append(nn.ReLU())\n            layers.append(nn.LayerNorm([width]))\n        for i in range(depth):\n            layers.append(nn.Linear(width, width))\n            layers.append(nn.ReLU())\n            layers.append(nn.LayerNorm([width]))\n        layers.append(nn.Linear(width, out_dim))\n        layers.append(nn.Softmax(dim=1))\n\n        self.mlp = nn.ModuleList(layers)\n        print(self.mlp)\n    \n    def forward(self, x):\n        for layer in self.mlp:\n            x = layer(x)\n        return x\n\ndef get_clip_model(clipmodel):\n    model, preprocess = clip.load(clipmodel, device=device, jit=False)\n    return model, preprocess\n\n# ================== HELPER FUNCTIONS =============================\ndef save_final_results(log_dir, name, mesh, mlp, vertices, colors, render, background):\n    mlp.eval()\n    with torch.no_grad():\n        probs = mlp(vertices)\n        max_idx = torch.argmax(probs, 1, keepdim=True)\n        # for renders\n        one_hot = torch.zeros(probs.shape).to(device)\n        one_hot = one_hot.scatter_(1, max_idx, 1)\n        sampled_mesh = mesh\n\n        highlight = torch.tensor([204, 255, 0]).to(device)\n        gray = torch.tensor([180, 180, 180]).to(device)\n        colors = torch.stack((highlight/255, gray/255)).to(device)\n        color_mesh(one_hot, sampled_mesh, colors)\n        rendered_images, _, _ = render.render_views(sampled_mesh, num_views=5,\n                                                                        show=False,\n                                                                        center_azim=0,\n                                                                        center_elev=0,\n                                                                        std=4,\n                                                                        return_views=True,\n                                                                        lighting=True,\n                                                                        background=background)\n        # for mesh\n        final_color = torch.zeros(vertices.shape[0], 3).to(device)\n        final_color = torch.where(max_idx==0, highlight, gray)\n        mesh.export(os.path.join(log_dir, f\"{name}.ply\"), extension=\"ply\", color=final_color)\n        save_renders(log_dir, 0, rendered_images, name='final_render.jpg')\ndef save_exp_config(config, output_dir):\n    import json, csv, os\n    # JSON\n    with open(os.path.join(output_dir, 'experiment_config.json'), 'w') as f:\n        json.dump(config, f, indent=2)\n    # CSV\n    csv_path = os.path.join(output_dir, 'experiments_summary.csv')\n    write_header = not os.path.exists(csv_path)\n    with open(csv_path, 'a', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=config.keys())\n        if write_header: writer.writeheader()\n        writer.writerow(config)\n\ndef clip_loss(rendered_images: torch.Tensor,\n              text_embedding: torch.Tensor,\n              clip_model: nn.Module,\n              clip_transform: transforms.Compose,\n              augment_transform: transforms.Compose,\n              n_augs: int,\n              clipavg: str = \"view\") -> torch.Tensor:\n    \"\"\"\n    Replichiamo esattamente la loss del codice ufficiale:\n    - n_augs==0: un solo forward con clip_transform\n    - n_augs>0: summation di n_augs forward con augment_transform\n    - clipavg=\"view\": media sulle viste prima di cosine‐similarity\n    - clipavg!=\"view\": media sulle coppie vista‐testo\n    \"\"\"\n    # caso senza augmentazioni\n    if n_augs == 0:\n        # 1) applica resize+normalize\n        clip_imgs = clip_transform(rendered_images)            # (V,3,H,W)\n        # 2) encode CLIP\n        enc = clip_model.encode_image(clip_imgs)               # (V,D)\n        enc = enc / enc.norm(dim=1, keepdim=True)\n\n        # 3) normalizza testo\n        txt = text_embedding / text_embedding.norm(dim=1, keepdim=True)\n\n        # 4) computa loss\n        if clipavg == \"view\":\n            if txt.shape[0] > 1:\n                # media viste vs media testo\n                loss = -torch.cosine_similarity(enc.mean(0),\n                                                txt.mean(0), dim=0)\n            else:\n                loss = -torch.cosine_similarity(enc.mean(0, keepdim=True),\n                                                txt, dim=1)\n        else:\n            loss = -torch.mean(torch.cosine_similarity(enc, txt, dim=1))\n\n    # caso con augmentazioni\n    else:\n        loss = 0.0\n        for _ in range(n_augs):\n            # 1) augment + normalize\n            aug = augment_transform(rendered_images)            # (V,3,H,W)\n            # 2) encode\n            enc_a = clip_model.encode_image(aug)\n            enc_a = enc_a / enc_a.norm(dim=1, keepdim=True)\n            # 3) testo normalizzato\n            txt = text_embedding / text_embedding.norm(dim=1, keepdim=True)\n\n            # 4) accumula loss (no division!)\n            if clipavg == \"view\":\n                if txt.shape[0] > 1:\n                    loss -= torch.cosine_similarity(enc_a.mean(0),\n                                                    txt.mean(0), dim=0)\n                else:\n                    loss -= torch.cosine_similarity(enc_a.mean(0, keepdim=True),\n                                                    txt, dim=1)\n            else:\n                loss -= torch.mean(torch.cosine_similarity(enc_a, txt, dim=1))\n\n    return loss\n\n\n    \ndef save_renders(dir, i, rendered_images, name=None):\n    if name is not None:\n        torchvision.utils.save_image(rendered_images, os.path.join(dir, name))\n    else:\n        torchvision.utils.save_image(rendered_images, os.path.join(dir, 'renders/iter_{}.jpg'.format(i)))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:04:36.029278Z","iopub.execute_input":"2025-07-28T10:04:36.029459Z","iopub.status.idle":"2025-07-28T10:04:42.785058Z","shell.execute_reply.started":"2025-07-28T10:04:36.029439Z","shell.execute_reply":"2025-07-28T10:04:42.784404Z"}},"outputs":[{"name":"stdout","text":"Warp 1.8.0 initialized:\n   CUDA Toolkit 12.8, Driver 12.6\n   Devices:\n     \"cpu\"      : \"x86_64\"\n     \"cuda:0\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n     \"cuda:1\"   : \"Tesla T4\" (15 GiB, sm_75, mempool enabled)\n   CUDA peer access:\n     Supported fully (all-directional)\n   Kernel cache:\n     /root/.cache/warp/1.8.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Constrain most sources of randomness\n# (some torch backwards functions within CLIP are non-determinstic)\nseed=exp_config[\"seed\"]\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\n\nrender_res = exp_config[\"render_res\"]\nlearning_rate = exp_config[\"learning_rate\"]\nn_iter = exp_config[\"n_iter\"]\nres = exp_config[\"render_res\"]\nobj_path = exp_config[\"obj_path\"]\nn_augs = exp_config[\"n_augs\"]\noutput_dir = exp_config[\"output_dir\"]\nclip_model = exp_config[\"clip_model_name\"]\n\nclip_model, preprocess = get_clip_model(clip_model)\n\nPath(os.path.join(output_dir, 'renders')).mkdir(parents=True, exist_ok=True)\n\nobjbase, extension = os.path.splitext(os.path.basename(obj_path))\n\nrender = Renderer(dim=(render_res, render_res))\nmesh = Mesh(obj_path)\nMeshNormalizer(mesh)()\n\n# Initialize variables\nbackground = torch.tensor((1., 1., 1.)).to(device)\n\nlog_dir = output_dir\n\n# CLIP and Augmentation Transforms\nclip_normalizer = transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\nclip_transform = transforms.Compose([\n    transforms.Resize((res, res), antialias=False),\n    clip_normalizer\n])\naugment_transform = transforms.Compose([\n    transforms.RandomResizedCrop(res, scale=(1, 1), antialias=False),\n    transforms.RandomPerspective(fill=1,\n                                 distortion_scale=exp_config[\"aug_params\"][\"distortion_scale\"],\n                                 p=exp_config[\"aug_params\"][\"p\"]),\n    clip_normalizer\n])\n\n# MLP Settings\nmlp = NeuralHighlighter(depth=exp_config[\"mlp_num_layers\"],\n    width=exp_config[\"mlp_hidden_dim\"],\n    out_dim=exp_config[\"mlp_out_dim\"],\n    input_dim=exp_config[\"mlp_input_dim\"],\n    positional_encoding=exp_config[\"positional_encoding\"],\n    sigma=exp_config[\"sigma\"]).to(device)\noptim = torch.optim.Adam(mlp.parameters(), learning_rate)\n\n# list of possible colors\nrgb_to_color = {(204/255, 1., 0.): \"highlighter\", (180/255, 180/255, 180/255): \"gray\"}\ncolor_to_rgb = {\"highlighter\": [204/255, 1., 0.], \"gray\": [180/255, 180/255, 180/255]}\nfull_colors = [[204/255, 1., 0.], [180/255, 180/255, 180/255]]\ncolors = torch.tensor(full_colors).to(device)\n\n\n# --- Prompt ---\n# encode prompt with CLIP\nprompt = exp_config[\"prompt\"]\n\nwith torch.no_grad():\n    prompt_token = clip.tokenize([prompt]).to(device)\n    encoded_text = clip_model.encode_text(prompt_token)\n    encoded_text = encoded_text / encoded_text.norm(dim=1, keepdim=True)\n\nvertices = copy.deepcopy(mesh.vertices)\nn_views = exp_config[\"n_views\"]\n\nbest_loss = float('inf')\nbest_iter = -1\nbest_state = None\n\nlosses = []\nstart_time = time.time()\n# Optimization loop\nfor i in tqdm(range(n_iter)):\n    optim.zero_grad()\n\n    # predict highlight probabilities\n    pred_class = mlp(vertices)\n\n    # color and render mesh\n    sampled_mesh = mesh\n    color_mesh(pred_class, sampled_mesh, colors)\n    rendered_images, elev, azim = render.render_views(sampled_mesh, num_views=n_views,\n                                                            show=False,\n                                                            center_azim=0,\n                                                            center_elev=0,\n                                                            std=4,\n                                                            return_views=True,\n                                                            lighting=True,\n                                                            background=background)\n\n    # Calculate CLIP Loss\n    loss = clip_loss(rendered_images,\n        encoded_text,\n        clip_model,\n        clip_transform,\n        augment_transform,\n        n_augs,\n        clipavg = exp_config[\"clipavg\"])\n    loss.backward()\n\n    optim.step()\n\n    # update variables + record loss\n    with torch.no_grad():\n        losses.append(loss.item())\n    # tracking del best\n    if loss.item() < best_loss:\n        best_loss  = loss.item()\n        best_iter  = i\n        best_state = copy.deepcopy(mlp.state_dict())\n        # opzionale: salva immediatamente anche le immagini\n        #save_renders(log_dir, f\"best_{best_iter}\", rendered_images)\n    # report results\n    if i % 100 == 0:\n        print(\"Last 100 CLIP score: {}\".format(np.mean(losses[-100:])))\n        save_renders(log_dir, i, rendered_images)\n        with open(os.path.join(log_dir, \"training_info.txt\"), \"a\") as f:\n            f.write(f\"For iteration {i}... Prompt: {prompt}, Last 100 avg CLIP score: {np.mean(losses[-100:])}, CLIP score {losses[-1]}\\n\")\n\n# metriche\nfinal_loss       = losses[-1]\nexp_config[\"final_clip_score\"]       = -final_loss\nexp_config[\"avg_clip_score_last100\"] = -float(np.mean(losses[-100:]))\nexp_config[\"runtime_seconds\"]        = time.time() - start_time\n# fine del loop: ricarica il modello al best_iter\nmlp.load_state_dict(best_state)\nexp_config[\"best_iter\"] = best_iter\nexp_config[\"best_clip_score\"] = -best_loss\n# salva config + summary\nsave_exp_config(exp_config, output_dir)\n# save results\nsave_final_results(log_dir, f\"{objbase}_best_iter{best_iter}\", mesh, mlp, vertices, colors, render, background)\n\n# Save prompts\nwith open(os.path.join(log_dir, \"prompt.txt\"), \"w\") as f:\n    f.write(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-28T10:04:42.785775Z","iopub.execute_input":"2025-07-28T10:04:42.786131Z"}},"outputs":[{"name":"stderr","text":"100%|███████████████████████████████████████| 890M/890M [00:18<00:00, 51.4MiB/s]\n","output_type":"stream"},{"name":"stdout","text":"ModuleList(\n  (0): Linear(in_features=3, out_features=256, bias=True)\n  (1): ReLU()\n  (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (3): Linear(in_features=256, out_features=256, bias=True)\n  (4): ReLU()\n  (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (6): Linear(in_features=256, out_features=256, bias=True)\n  (7): ReLU()\n  (8): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (9): Linear(in_features=256, out_features=256, bias=True)\n  (10): ReLU()\n  (11): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (12): Linear(in_features=256, out_features=256, bias=True)\n  (13): ReLU()\n  (14): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (15): Linear(in_features=256, out_features=256, bias=True)\n  (16): ReLU()\n  (17): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (18): Linear(in_features=256, out_features=256, bias=True)\n  (19): ReLU()\n  (20): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (21): Linear(in_features=256, out_features=256, bias=True)\n  (22): ReLU()\n  (23): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (24): Linear(in_features=256, out_features=256, bias=True)\n  (25): ReLU()\n  (26): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (27): Linear(in_features=256, out_features=2, bias=True)\n  (28): Softmax(dim=1)\n)\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 1/2500 [00:02<1:28:26,  2.12s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score: -1.57421875\n","output_type":"stream"},{"name":"stderr","text":"  4%|▍         | 101/2500 [02:56<1:13:20,  1.83s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score: -1.6928515625\n","output_type":"stream"},{"name":"stderr","text":"  8%|▊         | 201/2500 [06:02<1:12:24,  1.89s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score: -1.69857421875\n","output_type":"stream"},{"name":"stderr","text":" 12%|█▏        | 301/2500 [09:09<1:08:00,  1.86s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score: -1.7078515625\n","output_type":"stream"},{"name":"stderr","text":" 16%|█▌        | 401/2500 [12:14<1:05:19,  1.87s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score: -1.699345703125\n","output_type":"stream"},{"name":"stderr","text":" 20%|██        | 501/2500 [15:21<1:02:09,  1.87s/it]","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score: -1.711455078125\n","output_type":"stream"},{"name":"stderr","text":" 24%|██▍       | 601/2500 [18:27<59:08,  1.87s/it]  ","output_type":"stream"},{"name":"stdout","text":"Last 100 CLIP score: -1.7155078125\n","output_type":"stream"},{"name":"stderr","text":" 27%|██▋       | 686/2500 [21:05<56:27,  1.87s/it]","output_type":"stream"}],"execution_count":null}]}